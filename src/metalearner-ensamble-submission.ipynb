{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1227b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# =============================================================================\n",
    "# GPU CONFIGURATION\n",
    "# =============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"META-LEARNER, ENSEMBLE & SUBMISSION\")\n",
    "print(\"=\"*80)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ“ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    USE_GPU = True\n",
    "else:\n",
    "    print(\"âš  No GPU detected, using CPU\")\n",
    "    USE_GPU = False\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD PREPROCESSED DATA\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING PREPROCESSED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X_train = joblib.load('../data/preprocessed/X_train.pkl')\n",
    "X_test = joblib.load('../data/preprocessed/X_test.pkl')\n",
    "X_orig = joblib.load('../data/preprocessed/X_orig.pkl')\n",
    "y_train = joblib.load('../data/preprocessed/y_train.pkl')\n",
    "y_orig = joblib.load('../data/preprocessed/y_orig.pkl')\n",
    "metadata = joblib.load('../data/preprocessed/metadata.pkl')\n",
    "\n",
    "print(f\"âœ“ Train shape: {X_train.shape}\")\n",
    "print(f\"âœ“ Test shape: {X_test.shape}\")\n",
    "print(f\"âœ“ Original shape: {X_orig.shape}\")\n",
    "\n",
    "# Load original test for ID column\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD OPTIMIZED PARAMETERS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING OPTIMIZED PARAMETERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "params_lightgbm = joblib.load('../results/optimization/lightgbm_params.pkl')\n",
    "params_xgboost = joblib.load('../results/optimization/xgboost_params.pkl')\n",
    "params_catboost = joblib.load('../results/optimization/catboost_params.pkl')\n",
    "params_extratrees = joblib.load('../results/optimization/extratrees_params.pkl')\n",
    "params_gradientboosting = joblib.load('../results/optimization/gradientboosting_params.pkl')\n",
    "params_ridge = joblib.load('../results/optimization/ridge_params.pkl')\n",
    "params_elasticnet = joblib.load('../results/optimization/elasticnet_params.pkl')\n",
    "params_svr = joblib.load('../results/optimization/svr_params.pkl')\n",
    "\n",
    "print(\"âœ“ All 8 model parameters loaded\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING CONFIGURATION\n",
    "# =============================================================================\n",
    "N_FOLDS = 10\n",
    "y_bins = pd.qcut(y_train, q=10, labels=False, duplicates='drop')\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TRAINING CONFIGURATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Folds: {N_FOLDS}\")\n",
    "print(f\"Strategy: Stratified K-Fold\")\n",
    "\n",
    "# Storage for OOF and test predictions\n",
    "oof_predictions = {\n",
    "    'ridge': np.zeros(len(y_train)),\n",
    "    'elastic': np.zeros(len(y_train)),\n",
    "    'xgb': np.zeros(len(y_train)),\n",
    "    'lgb': np.zeros(len(y_train)),\n",
    "    'cat': np.zeros(len(y_train)),\n",
    "    'et': np.zeros(len(y_train)),\n",
    "    'gbr': np.zeros(len(y_train)),\n",
    "    'svr': np.zeros(len(y_train))\n",
    "}\n",
    "\n",
    "test_predictions = {\n",
    "    'ridge': np.zeros((len(X_test), N_FOLDS)),\n",
    "    'elastic': np.zeros((len(X_test), N_FOLDS)),\n",
    "    'xgb': np.zeros((len(X_test), N_FOLDS)),\n",
    "    'lgb': np.zeros((len(X_test), N_FOLDS)),\n",
    "    'cat': np.zeros((len(X_test), N_FOLDS)),\n",
    "    'et': np.zeros((len(X_test), N_FOLDS)),\n",
    "    'gbr': np.zeros((len(X_test), N_FOLDS)),\n",
    "    'svr': np.zeros((len(X_test), N_FOLDS))\n",
    "}\n",
    "\n",
    "best_iterations = {\n",
    "    'xgb': [],\n",
    "    'lgb': [],\n",
    "    'cat': []\n",
    "}\n",
    "\n",
    "# Storage for full models\n",
    "full_models = {}\n",
    "\n",
    "# =============================================================================\n",
    "# LEVEL 1: BASE MODELS TRAINING\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LEVEL 1: BASE MODELS TRAINING (8 MODELS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tqdm(skf.split(X_train, y_bins), \n",
    "                                                   total=N_FOLDS, \n",
    "                                                   desc=\"Training Folds\"), 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold}/{N_FOLDS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Split data\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # Augment with original data\n",
    "    X_tr_full = pd.concat([X_tr, X_orig], axis=0, ignore_index=True)\n",
    "    y_tr_full = np.concatenate([y_tr, y_orig])\n",
    "\n",
    "    print(f\"Training size: {len(X_tr_full):,} ({len(X_tr):,} synthetic + {len(X_orig):,} original)\")\n",
    "\n",
    "    # --- RIDGE ---\n",
    "    print(\"Ridge...\", end=\" \", flush=True)\n",
    "    scaler_ridge = RobustScaler()\n",
    "    X_tr_scaled = scaler_ridge.fit_transform(X_tr_full)\n",
    "    X_val_scaled = scaler_ridge.transform(X_val)\n",
    "    X_test_scaled = scaler_ridge.transform(X_test)\n",
    "\n",
    "    ridge = Ridge(**params_ridge)\n",
    "    ridge.fit(X_tr_scaled, y_tr_full)\n",
    "    oof_predictions['ridge'][val_idx] = np.clip(ridge.predict(X_val_scaled), 0, 100)\n",
    "    test_predictions['ridge'][:, fold-1] = np.clip(ridge.predict(X_test_scaled), 0, 100)\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_val, oof_predictions['ridge'][val_idx])):.5f}\")\n",
    "\n",
    "    # --- ELASTICNET ---\n",
    "    print(\"ElasticNet...\", end=\" \", flush=True)\n",
    "    elastic = ElasticNet(**params_elasticnet)\n",
    "    elastic.fit(X_tr_scaled, y_tr_full)\n",
    "    oof_predictions['elastic'][val_idx] = np.clip(elastic.predict(X_val_scaled), 0, 100)\n",
    "    test_predictions['elastic'][:, fold-1] = np.clip(elastic.predict(X_test_scaled), 0, 100)\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_val, oof_predictions['elastic'][val_idx])):.5f}\")\n",
    "\n",
    "    # --- XGBOOST ---\n",
    "    print(\"XGBoost...\", end=\" \", flush=True)\n",
    "    dtrain = xgb.DMatrix(X_tr_full, label=y_tr_full)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "    xgb_model = xgb.train(\n",
    "        params_xgboost,\n",
    "        dtrain,\n",
    "        num_boost_round=3000,\n",
    "        evals=[(dval, 'eval')],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    best_iterations['xgb'].append(xgb_model.best_iteration)\n",
    "    oof_predictions['xgb'][val_idx] = np.clip(xgb_model.predict(dval), 0, 100)\n",
    "    test_predictions['xgb'][:, fold-1] = np.clip(xgb_model.predict(dtest), 0, 100)\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_val, oof_predictions['xgb'][val_idx])):.5f} (iter: {xgb_model.best_iteration})\")\n",
    "\n",
    "    # --- LIGHTGBM ---\n",
    "    print(\"LightGBM...\", end=\" \", flush=True)\n",
    "    train_data = lgb.Dataset(X_tr_full, label=y_tr_full)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "    lgb_model = lgb.train(\n",
    "        params_lightgbm,\n",
    "        train_data,\n",
    "        num_boost_round=3000,\n",
    "        valid_sets=[val_data],\n",
    "        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]\n",
    "    )\n",
    "\n",
    "    best_iterations['lgb'].append(lgb_model.best_iteration)\n",
    "    oof_predictions['lgb'][val_idx] = np.clip(lgb_model.predict(X_val), 0, 100)\n",
    "    test_predictions['lgb'][:, fold-1] = np.clip(lgb_model.predict(X_test), 0, 100)\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_val, oof_predictions['lgb'][val_idx])):.5f} (iter: {lgb_model.best_iteration})\")\n",
    "\n",
    "    # --- CATBOOST ---\n",
    "    print(\"CatBoost...\", end=\" \", flush=True)\n",
    "    cat_model = CatBoostRegressor(**params_catboost)\n",
    "    cat_model.fit(X_tr_full, y_tr_full, eval_set=(X_val, y_val), verbose=False)\n",
    "\n",
    "    best_iterations['cat'].append(cat_model.get_best_iteration())\n",
    "    oof_predictions['cat'][val_idx] = np.clip(cat_model.predict(X_val), 0, 100)\n",
    "    test_predictions['cat'][:, fold-1] = np.clip(cat_model.predict(X_test), 0, 100)\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_val, oof_predictions['cat'][val_idx])):.5f} (iter: {cat_model.get_best_iteration()})\")\n",
    "\n",
    "    # --- EXTRATREES ---\n",
    "    print(\"ExtraTrees...\", end=\" \", flush=True)\n",
    "    et_model = ExtraTreesRegressor(**params_extratrees)\n",
    "    et_model.fit(X_tr_full, y_tr_full)\n",
    "    oof_predictions['et'][val_idx] = np.clip(et_model.predict(X_val), 0, 100)\n",
    "    test_predictions['et'][:, fold-1] = np.clip(et_model.predict(X_test), 0, 100)\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_val, oof_predictions['et'][val_idx])):.5f}\")\n",
    "\n",
    "    # --- GRADIENT BOOSTING ---\n",
    "    print(\"GradientBoosting...\", end=\" \", flush=True)\n",
    "    gbr_model = GradientBoostingRegressor(**params_gradientboosting)\n",
    "    gbr_model.fit(X_tr_full, y_tr_full)\n",
    "    oof_predictions['gbr'][val_idx] = np.clip(gbr_model.predict(X_val), 0, 100)\n",
    "    test_predictions['gbr'][:, fold-1] = np.clip(gbr_model.predict(X_test), 0, 100)\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_val, oof_predictions['gbr'][val_idx])):.5f}\")\n",
    "\n",
    "    # --- SVR ---\n",
    "    print(\"SVR...\", end=\" \", flush=True)\n",
    "    sample_size = min(100000, len(X_tr_full))\n",
    "    if len(X_tr_full) > sample_size:\n",
    "        idx = np.random.choice(len(X_tr_full), sample_size, replace=False)\n",
    "        X_tr_sample = X_tr_full.iloc[idx]\n",
    "        y_tr_sample = y_tr_full[idx]\n",
    "    else:\n",
    "        X_tr_sample = X_tr_full\n",
    "        y_tr_sample = y_tr_full\n",
    "\n",
    "    scaler_svr = StandardScaler()\n",
    "    X_tr_svr = scaler_svr.fit_transform(X_tr_sample)\n",
    "    X_val_svr = scaler_svr.transform(X_val)\n",
    "    X_test_svr = scaler_svr.transform(X_test)\n",
    "\n",
    "    svr_model = SVR(**params_svr)\n",
    "    svr_model.fit(X_tr_svr, y_tr_sample)\n",
    "    oof_predictions['svr'][val_idx] = np.clip(svr_model.predict(X_val_svr), 0, 100)\n",
    "    test_predictions['svr'][:, fold-1] = np.clip(svr_model.predict(X_test_svr), 0, 100)\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_val, oof_predictions['svr'][val_idx])):.5f}\")\n",
    "\n",
    "# Level 1 OOF scores\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"LEVEL 1 OOF SCORES\")\n",
    "print(f\"{'='*80}\")\n",
    "for model_name, oof in oof_predictions.items():\n",
    "    rmse = np.sqrt(mean_squared_error(y_train, oof))\n",
    "    print(f\"{model_name.upper():15s}: {rmse:.6f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FULL REFIT ON ALL DATA\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FULL REFIT: TRAINING ON 100% OF DATA\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "avg_best_iter_xgb = int(np.mean(best_iterations['xgb']))\n",
    "avg_best_iter_lgb = int(np.mean(best_iterations['lgb']))\n",
    "avg_best_iter_cat = int(np.mean(best_iterations['cat']))\n",
    "\n",
    "print(f\"\\nAverage best iterations from CV:\")\n",
    "print(f\"  XGBoost:  {avg_best_iter_xgb}\")\n",
    "print(f\"  LightGBM: {avg_best_iter_lgb}\")\n",
    "print(f\"  CatBoost: {avg_best_iter_cat}\")\n",
    "\n",
    "# Prepare full dataset\n",
    "X_full = pd.concat([X_train, X_orig], axis=0, ignore_index=True)\n",
    "y_full = np.concatenate([y_train, y_orig])\n",
    "\n",
    "print(f\"\\nFull training set size: {len(X_full):,} samples\")\n",
    "\n",
    "# Storage for full model predictions\n",
    "test_pred_full = {}\n",
    "\n",
    "print(\"\\nTraining final models on 100% data...\")\n",
    "\n",
    "# Ridge\n",
    "print(\"  Ridge...\", end=\" \", flush=True)\n",
    "scaler_full = RobustScaler()\n",
    "X_full_scaled = scaler_full.fit_transform(X_full)\n",
    "X_test_full_scaled = scaler_full.transform(X_test)\n",
    "\n",
    "ridge_full = Ridge(**params_ridge)\n",
    "ridge_full.fit(X_full_scaled, y_full)\n",
    "test_pred_full['ridge'] = np.clip(ridge_full.predict(X_test_full_scaled), 0, 100)\n",
    "full_models['ridge'] = {'model': ridge_full, 'scaler': scaler_full}\n",
    "print(\"âœ“\")\n",
    "\n",
    "# ElasticNet\n",
    "print(\"  ElasticNet...\", end=\" \", flush=True)\n",
    "elastic_full = ElasticNet(**params_elasticnet)\n",
    "elastic_full.fit(X_full_scaled, y_full)\n",
    "test_pred_full['elastic'] = np.clip(elastic_full.predict(X_test_full_scaled), 0, 100)\n",
    "full_models['elastic'] = {'model': elastic_full, 'scaler': scaler_full}\n",
    "print(\"âœ“\")\n",
    "\n",
    "# XGBoost\n",
    "print(\"  XGBoost...\", end=\" \", flush=True)\n",
    "dtrain_full = xgb.DMatrix(X_full, label=y_full)\n",
    "dtest_full = xgb.DMatrix(X_test)\n",
    "xgb_full = xgb.train(params_xgboost, dtrain_full, num_boost_round=avg_best_iter_xgb, verbose_eval=False)\n",
    "test_pred_full['xgb'] = np.clip(xgb_full.predict(dtest_full), 0, 100)\n",
    "full_models['xgb'] = xgb_full\n",
    "print(\"âœ“\")\n",
    "\n",
    "# LightGBM\n",
    "print(\"  LightGBM...\", end=\" \", flush=True)\n",
    "train_full_lgb = lgb.Dataset(X_full, label=y_full)\n",
    "lgb_full = lgb.train(params_lightgbm, train_full_lgb, num_boost_round=avg_best_iter_lgb, callbacks=[lgb.log_evaluation(0)])\n",
    "test_pred_full['lgb'] = np.clip(lgb_full.predict(X_test), 0, 100)\n",
    "full_models['lgb'] = lgb_full\n",
    "print(\"âœ“\")\n",
    "\n",
    "# CatBoost\n",
    "print(\"  CatBoost...\", end=\" \", flush=True)\n",
    "cat_params_full = params_catboost.copy()\n",
    "cat_params_full['iterations'] = avg_best_iter_cat\n",
    "cat_full = CatBoostRegressor(**cat_params_full)\n",
    "cat_full.fit(X_full, y_full)\n",
    "test_pred_full['cat'] = np.clip(cat_full.predict(X_test), 0, 100)\n",
    "full_models['cat'] = cat_full\n",
    "print(\"âœ“\")\n",
    "\n",
    "# ExtraTrees\n",
    "print(\"  ExtraTrees...\", end=\" \", flush=True)\n",
    "et_full = ExtraTreesRegressor(**params_extratrees)\n",
    "et_full.fit(X_full, y_full)\n",
    "test_pred_full['et'] = np.clip(et_full.predict(X_test), 0, 100)\n",
    "full_models['et'] = et_full\n",
    "print(\"âœ“\")\n",
    "\n",
    "# GradientBoosting\n",
    "print(\"  GradientBoosting...\", end=\" \", flush=True)\n",
    "gbr_full = GradientBoostingRegressor(**params_gradientboosting)\n",
    "gbr_full.fit(X_full, y_full)\n",
    "test_pred_full['gbr'] = np.clip(gbr_full.predict(X_test), 0, 100)\n",
    "full_models['gbr'] = gbr_full\n",
    "print(\"âœ“\")\n",
    "\n",
    "# SVR\n",
    "print(\"  SVR...\", end=\" \", flush=True)\n",
    "sample_size = min(100000, len(X_full))\n",
    "if len(X_full) > sample_size:\n",
    "    idx = np.random.choice(len(X_full), sample_size, replace=False)\n",
    "    X_full_sample = X_full.iloc[idx]\n",
    "    y_full_sample = y_full[idx]\n",
    "else:\n",
    "    X_full_sample = X_full\n",
    "    y_full_sample = y_full\n",
    "\n",
    "scaler_svr_full = StandardScaler()\n",
    "X_full_svr = scaler_svr_full.fit_transform(X_full_sample)\n",
    "X_test_svr = scaler_svr_full.transform(X_test)\n",
    "\n",
    "svr_full = SVR(**params_svr)\n",
    "svr_full.fit(X_full_svr, y_full_sample)\n",
    "test_pred_full['svr'] = np.clip(svr_full.predict(X_test_svr), 0, 100)\n",
    "full_models['svr'] = {'model': svr_full, 'scaler': scaler_svr_full}\n",
    "print(\"âœ“\")\n",
    "\n",
    "print(\"\\nâœ“ All models trained on full data!\")\n",
    "\n",
    "# Save full models\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "for model_name, model_obj in full_models.items():\n",
    "    joblib.dump(model_obj, f'../models/{model_name}_full.pkl')\n",
    "print(\"\\nâœ“ Full models saved!\")\n",
    "\n",
    "# =============================================================================\n",
    "# LEVEL 2: META-LEARNER STACKING\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"LEVEL 2: META-LEARNER STACKING\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Create meta-features\n",
    "meta_train = np.column_stack(list(oof_predictions.values()))\n",
    "meta_test = np.column_stack(list(test_pred_full.values()))\n",
    "\n",
    "# Add statistical features\n",
    "meta_train_enhanced = np.column_stack([\n",
    "    meta_train,\n",
    "    meta_train.mean(axis=1),\n",
    "    meta_train.std(axis=1),\n",
    "    meta_train.max(axis=1),\n",
    "    meta_train.min(axis=1)\n",
    "])\n",
    "\n",
    "meta_test_enhanced = np.column_stack([\n",
    "    meta_test,\n",
    "    meta_test.mean(axis=1),\n",
    "    meta_test.std(axis=1),\n",
    "    meta_test.max(axis=1),\n",
    "    meta_test.min(axis=1)\n",
    "])\n",
    "\n",
    "print(f\"Meta-features shape: {meta_train_enhanced.shape}\")\n",
    "\n",
    "# Train meta-learners\n",
    "oof_meta_ridge = np.zeros(len(y_train))\n",
    "oof_meta_lgb = np.zeros(len(y_train))\n",
    "oof_meta_xgb = np.zeros(len(y_train))\n",
    "\n",
    "test_meta_ridge = np.zeros((len(X_test), N_FOLDS))\n",
    "test_meta_lgb = np.zeros((len(X_test), N_FOLDS))\n",
    "test_meta_xgb = np.zeros((len(X_test), N_FOLDS))\n",
    "\n",
    "meta_models = {\n",
    "    'ridge': [],\n",
    "    'lgb': [],\n",
    "    'xgb': [],\n",
    "    'scalers': []\n",
    "}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(meta_train_enhanced, y_bins), 1):\n",
    "    print(f\"Meta-learner Fold {fold}/{N_FOLDS}...\", end=\" \")\n",
    "\n",
    "    X_tr_meta, X_val_meta = meta_train_enhanced[train_idx], meta_train_enhanced[val_idx]\n",
    "    y_tr_meta, y_val_meta = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # Ridge meta\n",
    "    scaler_meta = StandardScaler()\n",
    "    X_tr_meta_scaled = scaler_meta.fit_transform(X_tr_meta)\n",
    "    X_val_meta_scaled = scaler_meta.transform(X_val_meta)\n",
    "    X_test_meta_scaled = scaler_meta.transform(meta_test_enhanced)\n",
    "\n",
    "    ridge_meta = Ridge(alpha=1.0, random_state=42)\n",
    "    ridge_meta.fit(X_tr_meta_scaled, y_tr_meta)\n",
    "    oof_meta_ridge[val_idx] = np.clip(ridge_meta.predict(X_val_meta_scaled), 0, 100)\n",
    "    test_meta_ridge[:, fold-1] = np.clip(ridge_meta.predict(X_test_meta_scaled), 0, 100)\n",
    "    \n",
    "    meta_models['ridge'].append(ridge_meta)\n",
    "    meta_models['scalers'].append(scaler_meta)\n",
    "\n",
    "    # LightGBM meta\n",
    "    meta_lgb_params = {\n",
    "        'objective': 'regression', 'metric': 'rmse', 'learning_rate': 0.01,\n",
    "        'num_leaves': 15, 'max_depth': 4, 'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0,\n",
    "        'lambda_l2': 1.0, 'verbosity': -1, 'seed': 42\n",
    "    }\n",
    "\n",
    "    train_meta_data = lgb.Dataset(X_tr_meta, label=y_tr_meta)\n",
    "    val_meta_data = lgb.Dataset(X_val_meta, label=y_val_meta, reference=train_meta_data)\n",
    "\n",
    "    lgb_meta = lgb.train(\n",
    "        meta_lgb_params, train_meta_data, num_boost_round=1000,\n",
    "        valid_sets=[val_meta_data],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    oof_meta_lgb[val_idx] = np.clip(lgb_meta.predict(X_val_meta), 0, 100)\n",
    "    test_meta_lgb[:, fold-1] = np.clip(lgb_meta.predict(meta_test_enhanced), 0, 100)\n",
    "    \n",
    "    meta_models['lgb'].append(lgb_meta)\n",
    "\n",
    "    # XGBoost meta\n",
    "    dtrain_meta = xgb.DMatrix(X_tr_meta, label=y_tr_meta)\n",
    "    dval_meta = xgb.DMatrix(X_val_meta, label=y_val_meta)\n",
    "    dtest_meta = xgb.DMatrix(meta_test_enhanced)\n",
    "\n",
    "    meta_xgb_params = {\n",
    "        'objective': 'reg:squarederror', 'eval_metric': 'rmse',\n",
    "        'learning_rate': 0.01, 'max_depth': 3, 'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8, 'lambda': 2.0, 'alpha': 1.0, 'seed': 42\n",
    "    }\n",
    "\n",
    "    xgb_meta = xgb.train(\n",
    "        meta_xgb_params, dtrain_meta, num_boost_round=1000,\n",
    "        evals=[(dval_meta, 'eval')],\n",
    "        early_stopping_rounds=50, verbose_eval=False\n",
    "    )\n",
    "    oof_meta_xgb[val_idx] = np.clip(xgb_meta.predict(dval_meta), 0, 100)\n",
    "    test_meta_xgb[:, fold-1] = np.clip(xgb_meta.predict(dtest_meta), 0, 100)\n",
    "    \n",
    "    meta_models['xgb'].append(xgb_meta)\n",
    "\n",
    "    print(f\"âœ“\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"LEVEL 2 META-LEARNER OOF SCORES\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Ridge Meta:    {np.sqrt(mean_squared_error(y_train, oof_meta_ridge)):.6f}\")\n",
    "print(f\"LightGBM Meta: {np.sqrt(mean_squared_error(y_train, oof_meta_lgb)):.6f}\")\n",
    "print(f\"XGBoost Meta:  {np.sqrt(mean_squared_error(y_train, oof_meta_xgb)):.6f}\")\n",
    "\n",
    "# Save meta-learner models\n",
    "joblib.dump(meta_models, '../models/meta_models.pkl')\n",
    "print(\"\\nâœ“ Meta-learner models saved!\")\n",
    "\n",
    "# =============================================================================\n",
    "# OPTIMAL ENSEMBLE\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"OPTIMIZING FINAL ENSEMBLE\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "def ensemble_rmse_final(weights, *args):\n",
    "    oof_preds, y_true = args\n",
    "    weights = np.abs(weights) / np.sum(np.abs(weights))\n",
    "    ensemble = sum(w * pred for w, pred in zip(weights, oof_preds))\n",
    "    ensemble = np.clip(ensemble, 0, 100)\n",
    "    return np.sqrt(mean_squared_error(y_true, ensemble))\n",
    "\n",
    "# Combine all predictions\n",
    "all_oof_preds = list(oof_predictions.values()) + [\n",
    "    oof_meta_ridge, oof_meta_lgb, oof_meta_xgb\n",
    "]\n",
    "\n",
    "all_test_preds = list(test_pred_full.values()) + [\n",
    "    test_meta_ridge.mean(axis=1),\n",
    "    test_meta_lgb.mean(axis=1),\n",
    "    test_meta_xgb.mean(axis=1)\n",
    "]\n",
    "\n",
    "# Optimize weights\n",
    "initial_weights = np.ones(len(all_oof_preds)) / len(all_oof_preds)\n",
    "\n",
    "result = minimize(\n",
    "    ensemble_rmse_final, initial_weights, args=(all_oof_preds, y_train),\n",
    "    method='Nelder-Mead',\n",
    "    options={'maxiter': 2000, 'xatol': 1e-8, 'fatol': 1e-8}\n",
    ")\n",
    "\n",
    "optimal_weights = np.abs(result.x) / np.sum(np.abs(result.x))\n",
    "\n",
    "print(\"\\nOptimal weights:\")\n",
    "model_names = list(oof_predictions.keys()) + ['ridge_meta', 'lgb_meta', 'xgb_meta']\n",
    "for name, weight in zip(model_names, optimal_weights):\n",
    "    if weight > 0.01:\n",
    "        print(f\"  {name:15s}: {weight:.4f}\")\n",
    "\n",
    "# Create final ensemble\n",
    "final_oof = sum(w * pred for w, pred in zip(optimal_weights, all_oof_preds))\n",
    "final_oof = np.clip(final_oof, 0, 100)\n",
    "\n",
    "final_test = sum(w * pred for w, pred in zip(optimal_weights, all_test_preds))\n",
    "final_test = np.clip(final_test, 0, 100)\n",
    "\n",
    "final_oof_rmse = np.sqrt(mean_squared_error(y_train, final_oof))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL ENSEMBLE PERFORMANCE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Final OOF RMSE: {final_oof_rmse:.6f}\")\n",
    "\n",
    "best_single = min([np.sqrt(mean_squared_error(y_train, pred)) for pred in all_oof_preds])\n",
    "print(f\"Best single model: {best_single:.6f}\")\n",
    "print(f\"Improvement: {best_single - final_oof_rmse:.6f}\")\n",
    "\n",
    "# Save ensemble configuration\n",
    "ensemble_config = {\n",
    "    'weights': optimal_weights,\n",
    "    'model_names': model_names,\n",
    "    'weights_dict': {name: weight for name, weight in zip(model_names, optimal_weights)},\n",
    "    'final_oof_rmse': final_oof_rmse\n",
    "}\n",
    "joblib.dump(ensemble_config, '../models/ensemble_config.pkl')\n",
    "print(\"\\nâœ“ Ensemble configuration saved!\")\n",
    "\n",
    "# =============================================================================\n",
    "# POST-PROCESSING & CALIBRATION\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"POST-PROCESSING & CALIBRATION\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "def calibrate_predictions(train_preds, train_true, test_preds):\n",
    "    \"\"\"Apply isotonic regression calibration\"\"\"\n",
    "    iso_reg = IsotonicRegression(out_of_bounds='clip')\n",
    "    iso_reg.fit(train_preds, train_true)\n",
    "    test_calibrated = iso_reg.predict(test_preds)\n",
    "    return np.clip(test_calibrated, 0, 100)\n",
    "\n",
    "# Apply calibration\n",
    "final_test_calibrated = calibrate_predictions(final_oof, y_train, final_test)\n",
    "\n",
    "# Check if calibration improves OOF score\n",
    "print(\"Testing calibration effectiveness...\")\n",
    "final_oof_calibrated = calibrate_predictions(\n",
    "    final_oof[::2], y_train[::2],  # Train on even indices\n",
    "    final_oof[1::2]  # Test on odd indices\n",
    ")\n",
    "\n",
    "# Create full calibrated OOF\n",
    "calibrated_oof = final_oof.copy()\n",
    "calibrated_oof[1::2] = final_oof_calibrated\n",
    "\n",
    "calibrated_rmse = np.sqrt(mean_squared_error(y_train, calibrated_oof))\n",
    "print(f\"Original OOF RMSE:   {final_oof_rmse:.6f}\")\n",
    "print(f\"Calibrated OOF RMSE: {calibrated_rmse:.6f}\")\n",
    "\n",
    "if calibrated_rmse < final_oof_rmse:\n",
    "    print(\"âœ“ Using calibrated predictions (improvement detected)\")\n",
    "    final_submission = final_test_calibrated\n",
    "    final_rmse = calibrated_rmse\n",
    "else:\n",
    "    print(\"âœ“ Using original predictions (no improvement from calibration)\")\n",
    "    final_submission = final_test\n",
    "    final_rmse = final_oof_rmse\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL STATISTICS & SUBMISSION\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL STATISTICS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nPrediction Statistics:\")\n",
    "print(f\"  Train target - Mean: {y_train.mean():.2f}, Std: {y_train.std():.2f}, Min: {y_train.min():.2f}, Max: {y_train.max():.2f}\")\n",
    "print(f\"  OOF preds    - Mean: {final_oof.mean():.2f}, Std: {final_oof.std():.2f}, Min: {final_oof.min():.2f}, Max: {final_oof.max():.2f}\")\n",
    "print(f\"  Test preds   - Mean: {final_submission.mean():.2f}, Std: {final_submission.std():.2f}, Min: {final_submission.min():.2f}, Max: {final_submission.max():.2f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL PERFORMANCE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"âœ“ Final OOF RMSE: {final_rmse:.6f}\")\n",
    "print(f\"âœ“ Expected LB Score: ~{final_rmse:.4f} (Â±0.002)\")\n",
    "print(f\"\\nðŸŽ¯ Target beaten: {final_rmse < 8.54414}\")\n",
    "\n",
    "# Create submission\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'exam_score': final_submission\n",
    "})\n",
    "\n",
    "submission.to_csv('../results/submission.csv', index=False)\n",
    "print(f\"\\nâœ“ Submission saved to ../results/submission.csv\")\n",
    "\n",
    "# Save OOF predictions\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "oof_df = pd.DataFrame({\n",
    "    'id': train_df['id'],\n",
    "    'exam_score': y_train,\n",
    "    'prediction': final_oof\n",
    "})\n",
    "oof_df.to_csv('../results/oof_predictions.csv', index=False)\n",
    "print(\"âœ“ OOF predictions saved to ../results/oof_predictions.csv\")\n",
    "\n",
    "# Save individual model OOF predictions for analysis\n",
    "oof_detailed = pd.DataFrame({\n",
    "    'id': train_df['id'],\n",
    "    'exam_score': y_train\n",
    "})\n",
    "for model_name, oof in oof_predictions.items():\n",
    "    oof_detailed[f'oof_{model_name}'] = oof\n",
    "\n",
    "oof_detailed['oof_ridge_meta'] = oof_meta_ridge\n",
    "oof_detailed['oof_lgb_meta'] = oof_meta_lgb\n",
    "oof_detailed['oof_xgb_meta'] = oof_meta_xgb\n",
    "oof_detailed['oof_final_ensemble'] = final_oof\n",
    "\n",
    "oof_detailed.to_csv('../results/oof_predictions_detailed.csv', index=False)\n",
    "print(\"âœ“ Detailed OOF predictions saved to ../results/oof_predictions_detailed.csv\")\n",
    "\n",
    "# Save model comparison\n",
    "model_comparison = pd.DataFrame({\n",
    "    'model': model_names,\n",
    "    'oof_rmse': [np.sqrt(mean_squared_error(y_train, pred)) for pred in all_oof_preds],\n",
    "    'ensemble_weight': optimal_weights\n",
    "}).sort_values('oof_rmse')\n",
    "\n",
    "model_comparison.to_csv('../results/model_comparison.csv', index=False)\n",
    "print(\"âœ“ Model comparison saved to ../results/model_comparison.csv\")\n",
    "\n",
    "# Save best iterations info\n",
    "best_iterations_df = pd.DataFrame({\n",
    "    'model': ['XGBoost', 'LightGBM', 'CatBoost'],\n",
    "    'avg_best_iteration': [avg_best_iter_xgb, avg_best_iter_lgb, avg_best_iter_cat],\n",
    "    'iterations_per_fold': [\n",
    "        str(best_iterations['xgb']),\n",
    "        str(best_iterations['lgb']),\n",
    "        str(best_iterations['cat'])\n",
    "    ]\n",
    "})\n",
    "best_iterations_df.to_csv('../results/best_iterations.csv', index=False)\n",
    "print(\"âœ“ Best iterations saved to ../results/best_iterations.csv\")\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL SUMMARY\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TRAINING PIPELINE COMPLETE!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nðŸ“Š PERFORMANCE SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Final OOF RMSE:        {final_rmse:.6f}\")\n",
    "print(f\"Best Single Model:     {best_single:.6f}\")\n",
    "print(f\"Ensemble Improvement:  {best_single - final_rmse:.6f}\")\n",
    "print(f\"\\nðŸ† TOP 3 MODELS BY OOF RMSE:\")\n",
    "top_3 = model_comparison.head(3)\n",
    "for idx, row in top_3.iterrows():\n",
    "    print(f\"  {row['model']:15s}: {row['oof_rmse']:.6f} (weight: {row['ensemble_weight']:.4f})\")\n",
    "\n",
    "print(f\"\\nðŸ“ SAVED FILES\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Models (../models/):\")\n",
    "print(f\"  âœ“ ridge_full.pkl\")\n",
    "print(f\"  âœ“ elastic_full.pkl\")\n",
    "print(f\"  âœ“ xgb_full.pkl\")\n",
    "print(f\"  âœ“ lgb_full.pkl\")\n",
    "print(f\"  âœ“ cat_full.pkl\")\n",
    "print(f\"  âœ“ et_full.pkl\")\n",
    "print(f\"  âœ“ gbr_full.pkl\")\n",
    "print(f\"  âœ“ svr_full.pkl\")\n",
    "print(f\"  âœ“ meta_models.pkl (Ridge + LightGBM + XGBoost meta-learners)\")\n",
    "print(f\"  âœ“ ensemble_config.pkl\")\n",
    "\n",
    "print(f\"\\nResults (../results/):\")\n",
    "print(f\"  âœ“ submission.csv (READY FOR KAGGLE)\")\n",
    "print(f\"  âœ“ oof_predictions.csv\")\n",
    "print(f\"  âœ“ oof_predictions_detailed.csv\")\n",
    "print(f\"  âœ“ model_comparison.csv\")\n",
    "print(f\"  âœ“ best_iterations.csv\")\n",
    "\n",
    "print(f\"\\nOptimization Results (../results/optimization/):\")\n",
    "print(f\"  âœ“ lightgbm_params.pkl + history + study\")\n",
    "print(f\"  âœ“ xgboost_params.pkl + history + study\")\n",
    "print(f\"  âœ“ catboost_params.pkl + history + study\")\n",
    "print(f\"  âœ“ extratrees_params.pkl + history + study\")\n",
    "print(f\"  âœ“ gradientboosting_params.pkl + history + study\")\n",
    "print(f\"  âœ“ ridge_params.pkl + history + study\")\n",
    "print(f\"  âœ“ elasticnet_params.pkl + history + study\")\n",
    "print(f\"  âœ“ svr_params.pkl + history + study\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ðŸŽ‰ ALL DONE! Submission ready for Kaggle!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nðŸ’¡ Next Steps:\")\n",
    "print(f\"  1. Review model_comparison.csv to see individual model performance\")\n",
    "print(f\"  2. Check oof_predictions_detailed.csv for model-by-model predictions\")\n",
    "print(f\"  3. Upload submission.csv to Kaggle\")\n",
    "print(f\"  4. If needed, adjust ensemble weights in ensemble_config.pkl\")\n",
    "print(f\"\\nâœ¨ Good luck with your submission!\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
